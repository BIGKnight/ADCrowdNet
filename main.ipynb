{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import DME_deformable\n",
    "x = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"input\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, None, None, 1], name=\"label\")\n",
    "estimated_density_map, front_end = DME_deformable.DME_model(x, 1, 384, 512)\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    variable_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variable_names)\n",
    "    for k,v in zip(variable_names, values):\n",
    "        print(\"Variable: \", k, \"Shape: \", v.shape)\n",
    "        print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import DME_deformable\n",
    "import DME\n",
    "\n",
    "result_output = open(\"/home/zzn/SANet_implementation-master/result_B_12.13.txt\", \"w\")\n",
    "image_train_path = \"/home/zzn/part_B_final/train_data/images_train.npy\"\n",
    "gt_train_path = \"/home/zzn/part_B_final/train_data/gt_train.npy\"\n",
    "image_validate_path = \"/home/zzn/part_B_final/train_data/images_validate.npy\"\n",
    "gt_validate_path = \"/home/zzn/part_B_final/train_data/gt_validate.npy\"\n",
    "batch_size = 1\n",
    "epoch = 500\n",
    "MAE = 19970305\n",
    "if __name__ == '__main__':\n",
    "    image_train = np.load(image_train_path)\n",
    "    gt_train = np.load(gt_train_path)\n",
    "    image_validate = np.load(image_validate_path)\n",
    "    gt_validate = np.load(gt_validate_path)\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"input\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, None, None, 1], name=\"label\")\n",
    "\n",
    "    estimated_density_map, front_end, tmp_front_end, tmp_inception_value, tmp_1x1_value = DME_deformable.DME_model(x, 1, 384, 512)\n",
    "    # estimated_density_map, front_end, tmp_front_end, tmp_inception_value, tmp_1x1_value = DME.DME_model(x)\n",
    "\n",
    "    estimated_counting = tf.reduce_sum(estimated_density_map, reduction_indices=[1, 2, 3], name='estimated_counting')\n",
    "    gt_counting = tf.cast(tf.reduce_sum(y, reduction_indices=[1, 2, 3]), tf.float32)\n",
    "\n",
    "    sum_filter = tf.constant([1. for i in range(64)], dtype=tf.float32, shape=[8, 8, 1, 1])\n",
    "    gt_map = tf.nn.conv2d(y, sum_filter, [1, 8, 8, 1], padding='SAME')\n",
    "\n",
    "    loss = tf.squeeze(\n",
    "        tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.square(estimated_density_map - gt_map),\n",
    "                reduction_indices=[1, 2, 3]),\n",
    "            axis=0, name='loss')\n",
    "        / 2)\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(1e-5).minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    AE_batch = tf.abs(tf.subtract(estimated_counting, gt_counting))\n",
    "    SE_batch = tf.square(tf.subtract(gt_counting, estimated_counting))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # init the Variables\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        image_train_num = len(image_train)\n",
    "        step = 0\n",
    "        for i in range(epoch):\n",
    "            shuffle_batch = np.random.permutation(image_train_num // batch_size)\n",
    "            for j in range(image_train_num // batch_size):\n",
    "\n",
    "                # validate\n",
    "                if step % 50 == 0:\n",
    "                    loss_ = []\n",
    "                    MAE_ = []\n",
    "                    MSE_ = []\n",
    "                    for k in range(len(image_validate // batch_size)):\n",
    "                        loss_eval, batch_average_error, batch_square_error = sess.run([loss, AE_batch, SE_batch],\n",
    "                                                                                      feed_dict={x: image_validate[\n",
    "                                                                                                    k:k + batch_size],\n",
    "                                                                                                 y: gt_validate[\n",
    "                                                                                                    k:k + batch_size]})\n",
    "                        loss_.append(loss_eval)\n",
    "                        MAE_.append(batch_average_error)\n",
    "                        MSE_.append(batch_square_error)\n",
    "                    #                         print(k, batch_average_error)\n",
    "\n",
    "                    loss_ = np.reshape(loss_, [-1])\n",
    "                    MAE_ = np.reshape(MAE_, [-1])\n",
    "                    MSE_ = np.reshape(MSE_, [-1])\n",
    "                    # print(loss_)\n",
    "                    # print(MAE_)\n",
    "                    #                     print(MSE_)\n",
    "                    # calculate the validate loss, validate MAE and validate RMSE\n",
    "                    validate_loss = np.mean(loss_)\n",
    "                    validate_MAE = np.mean(MAE_)\n",
    "                    validate_RMSE = np.sqrt(np.mean(MSE_))\n",
    "\n",
    "                    # show one of the validate samples\n",
    "                    figure, ((origin, density_gt), (pred, front_ground)) = plt.subplots(2, 2, figsize=(20, 4))\n",
    "                    origin.imshow(image_validate[1])\n",
    "                    origin.set_title('Origin Image')\n",
    "\n",
    "                    front_g, gt_validate_down_sampling_map, predict_den, gt_counts, pred_counts, front_end_value, inception_value, conv1x1_value = sess.run(\n",
    "                        [front_end, gt_map, estimated_density_map, gt_counting, estimated_counting, tmp_front_end, tmp_inception_value, tmp_1x1_value],\n",
    "                        feed_dict={x: image_validate[1:2], y: gt_validate[1:2]})\n",
    "\n",
    "                    density_gt.imshow(np.squeeze(gt_validate_down_sampling_map), cmap=plt.cm.jet)\n",
    "                    density_gt.set_title('ground_truth')\n",
    "\n",
    "                    predict_den = np.squeeze(predict_den)\n",
    "                    pred.imshow(predict_den, cmap=plt.cm.jet)\n",
    "                    pred.set_title('back_end')\n",
    "                    front_ground.imshow(np.squeeze(front_g), cmap=plt.cm.jet)\n",
    "                    front_ground.set_title('front_end')\n",
    "\n",
    "                    plt.suptitle(\"one sample from the validate\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # show the validate MAE and MSE values on stdout\n",
    "                    gt_counts = np.squeeze(gt_counts)\n",
    "                    pred_counts = np.squeeze(pred_counts)\n",
    "\n",
    "                    sys.stdout.write(\n",
    "                        'The gt counts of the above sample:{}, and the pred counts:{}, vgg:{}, inception_1:{}, conv1x1:{}\\n'.format(gt_counts, pred_counts, front_end_value, inception_value, conv1x1_value))\n",
    "                    sys.stdout.write(\n",
    "                        'In step {}, epoch {}, with loss {}, MAE = {}, MSE = {}\\n'.format(step, i + 1, validate_loss,\n",
    "                                                                                          validate_MAE, validate_RMSE))\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                    # save model\n",
    "                    if MAE > validate_MAE:\n",
    "                        MAE = validate_MAE\n",
    "                        saver.save(sess, './checkpoint_dir/MyModel_deformable')\n",
    "\n",
    "                # train\n",
    "                start = (shuffle_batch[j] * batch_size) % image_train_num\n",
    "                end = min(start + batch_size, image_train_num)\n",
    "                sess.run(train_op, feed_dict={x: image_train[start:end], y: gt_train[start:end]})\n",
    "                step = step + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]]\n",
      "\n",
      "  [[1.]]]\n",
      "\n",
      "\n",
      " [[[1.]]\n",
      "\n",
      "  [[1.]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sum_filter = tf.constant([1., 1., 1., 1.], dtype=tf.float32, shape=[2, 2, 1, 1])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
