{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-495c779361ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import ADCrowdNet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import DME\n",
    "result_output = open(\"/home/zzn/SANet_implementation-master/result_B_12.13.txt\", \"w\")\n",
    "image_train_path = \"/home/zzn/part_B_final/train_data/images_train.npy\"\n",
    "gt_train_path = \"/home/zzn/part_B_final/train_data/gt_train.npy\"\n",
    "image_validate_path = \"/home/zzn/part_B_final/train_data/images_validate.npy\"\n",
    "gt_validate_path = \"/home/zzn/part_B_final/train_data/gt_validate.npy\"\n",
    "batch_size = 1\n",
    "epoch = 500\n",
    "MAE = 19970305\n",
    "if __name__ == '__main__':\n",
    "    image_train = np.load(image_train_path)\n",
    "    gt_train = np.load(gt_train_path)\n",
    "    image_validate = np.load(image_validate_path)\n",
    "    gt_validate = np.load(gt_validate_path)\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"input\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, None, None, 1], name=\"label\")\n",
    "    \n",
    "    estimated_density_map, init_vgg16_fn = DME.DME_model(x)\n",
    "    estimated_counting = tf.reduce_sum(estimated_density_map, reduction_indices=[1, 2, 3], name='estimated_counting')\n",
    "    gt_counting = tf.cast(tf.reduce_sum(y, reduction_indices=[1, 2, 3]), tf.float32)\n",
    "    \n",
    "    sum_filter = tf.constant([1. for i in range(64)], dtype=tf.float32, shape=[8, 8, 1, 1])\n",
    "    gt_map = tf.nn.conv2d(y, sum_filter, [1, 8, 8, 1], padding='SAME')\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.square(estimated_density_map - gt_map), reduction_indices=[1, 2, 3])\n",
    "    loss = tf.squeeze(tf.reduce_mean(loss, axis=0) / 2)\n",
    "    train_op = tf.train.AdamOptimizer(1e-5).minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    AE_batch = tf.abs(tf.subtract(estimated_counting, gt_counting))\n",
    "    SE_batch = tf.square(tf.subtract(ground_truth_counting, estimated_counting))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # init the Variables\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        init_vgg16_fn(sess)\n",
    "        image_train_num = len(image_train)\n",
    "        step = 0\n",
    "        for i in range(epoch):\n",
    "            shuffle_batch = np.random.permutation(image_train_num // batch_size)\n",
    "            for j in range(image_train_num // batch_size):\n",
    "                # train\n",
    "                start = (shuffle_batch[j] * batch_size) % image_train_num\n",
    "                end = min(start + batch_size, image_train_num)\n",
    "                sess.run(train_op, feed_dict={x: image_train[start:end], y: gt_train[start:end]})\n",
    "                step = step + 1\n",
    "                \n",
    "                #validate\n",
    "                if step%500 == 0:\n",
    "                    loss_ = []\n",
    "                    MAE_ = []\n",
    "                    MSE_ = []\n",
    "                    for k in range(len(image_validate // batch_size)):\n",
    "                        loss_eval, batch_average_error, batch_square_error = sess.run([loss, AE_batch, SE_batch], feed_dict={x: image_validate[k:k+batch_size], y: gt_validate[k:k+batch_size]})\n",
    "                        loss_.append(loss_eval)\n",
    "                        MAE_.append(batch_average_error)\n",
    "                        MSE_.append(batch_square_error)\n",
    "                    \n",
    "                    loss_ = np.reshape(loss_, [-1])\n",
    "                    MAE_ = np.reshape(MAE_, [-1])\n",
    "                    MSE_ = np.reshape(MSE_, [-1])\n",
    "                    \n",
    "                    # calculate the validate loss, validate MAE and validate RMSE\n",
    "                    validate_loss = np.mean(loss_)\n",
    "                    validate_MAE = np.mean(MAE_)\n",
    "                    validate_RMSE = np.sqrt(np.mean(MSE_))\n",
    "                    \n",
    "                     # show one of the validate samples\n",
    "                    figure, (origin, density_gt, pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "                    origin.imshow(image_validate[1])\n",
    "                    origin.set_title('Origin Image')\n",
    "                    gt_validate_down_sampling_map = sess,ru\n",
    "                    density_gt.imshow(np.squeeze(gt_validate[1]), cmap=plt.cm.jet)\n",
    "                    density_gt.set_title('ground_truth')\n",
    "                    predict_den, gt_counts, pred_counts = sess.run([estimated_density_map, ground_truth_counting, estimated_counting], feed_dict={x: image_validate[1:2], y: gt_validate[1:2]})\n",
    "                    predict_den = np.squeeze(predict_den)\n",
    "                    pred.imshow(predict_den, cmap = plt.cm.jet)\n",
    "                    plt.suptitle(\"one sample from the validate\")\n",
    "                    plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6035a99ca3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfront_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADCrowdNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mADCrowdNet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "front_end, init_fn = ADCrowdNet.ADCrowdNet_model(inputs)\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "init_fn(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 2.]\n",
      "   [1. 2.]\n",
      "   [1. 2.]]\n",
      "\n",
      "  [[1. 2.]\n",
      "   [1. 2.]\n",
      "   [1. 2.]]\n",
      "\n",
      "  [[1. 2.]\n",
      "   [1. 2.]\n",
      "   [1. 2.]]]\n",
      "\n",
      "\n",
      " [[[1. 2.]\n",
      "   [1. 2.]\n",
      "   [1. 2.]]\n",
      "\n",
      "  [[1. 2.]\n",
      "   [1. 2.]\n",
      "   [1. 2.]]\n",
      "\n",
      "  [[1. 2.]\n",
      "   [1. 2.]\n",
      "   [1. 2.]]]]\n",
      "[[[[3.]\n",
      "   [3.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [3.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [3.]\n",
      "   [3.]]]\n",
      "\n",
      "\n",
      " [[[3.]\n",
      "   [3.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [3.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [3.]\n",
      "   [3.]]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    w1 = tf.constant([[1., 2.], [3., 4.]])\n",
    "    w2 = tf.constant([[[[1., 2., 3.] for i in range(3)] for j in range(3)], [[[1., 2., 3.] for i in range(3)] for j in range(3)]])\n",
    "#     w2= tf.split(w2, 2, 0)\n",
    "#     w3 = tf.nn.softmax(w1, 1)\n",
    "#     w1 = tf.split(w1, 2, 0)\n",
    "#     lit = []\n",
    "#     for i, j in zip(w1, w2):\n",
    "#         i = tf.squeeze(i)\n",
    "#         fb, fc = tf.split(j, 2, 3)\n",
    "#         lit.append(i[0] * fb + i[1] * fc)\n",
    "#     print(sess.run(w3))\n",
    "#     print(sess.run(tf.concat(lit, 0)))\n",
    "#     lit = []\n",
    "#     for i, j in zip(w1, w2):\n",
    "#         fb, fc = tf.split(j, 2, axis=3)\n",
    "#         lit.append(i[0] * fb + i[1] * fc)\n",
    "    offset = tf.slice(w2, [0, 0, 0, 0], [2, 3, 3, 2])\n",
    "    mask = tf.slice(w2, [0, 0, 0, 2], [2, 3, 3, 1])\n",
    "    print(sess.run(offset))\n",
    "    print(sess.run(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 8\n",
      "[[[[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]\n",
      "\n",
      "  [[0 1 2 0 1 2 0 1 2]\n",
      "   [1 2 3 1 2 3 1 2 3]\n",
      "   [2 3 4 2 3 4 2 3 4]\n",
      "   [3 4 5 3 4 5 3 4 5]\n",
      "   [4 5 6 4 5 6 4 5 6]\n",
      "   [5 6 7 5 6 7 5 6 7]]]]\n",
      "[[[[ 0  0  0  1  1  1  2  2  2]\n",
      "   [ 0  0  0  1  1  1  2  2  2]\n",
      "   [ 0  0  0  1  1  1  2  2  2]\n",
      "   [ 0  0  0  1  1  1  2  2  2]\n",
      "   [ 0  0  0  1  1  1  2  2  2]\n",
      "   [ 0  0  0  1  1  1  2  2  2]]\n",
      "\n",
      "  [[ 1  1  1  2  2  2  3  3  3]\n",
      "   [ 1  1  1  2  2  2  3  3  3]\n",
      "   [ 1  1  1  2  2  2  3  3  3]\n",
      "   [ 1  1  1  2  2  2  3  3  3]\n",
      "   [ 1  1  1  2  2  2  3  3  3]\n",
      "   [ 1  1  1  2  2  2  3  3  3]]\n",
      "\n",
      "  [[ 2  2  2  3  3  3  4  4  4]\n",
      "   [ 2  2  2  3  3  3  4  4  4]\n",
      "   [ 2  2  2  3  3  3  4  4  4]\n",
      "   [ 2  2  2  3  3  3  4  4  4]\n",
      "   [ 2  2  2  3  3  3  4  4  4]\n",
      "   [ 2  2  2  3  3  3  4  4  4]]\n",
      "\n",
      "  [[ 3  3  3  4  4  4  5  5  5]\n",
      "   [ 3  3  3  4  4  4  5  5  5]\n",
      "   [ 3  3  3  4  4  4  5  5  5]\n",
      "   [ 3  3  3  4  4  4  5  5  5]\n",
      "   [ 3  3  3  4  4  4  5  5  5]\n",
      "   [ 3  3  3  4  4  4  5  5  5]]\n",
      "\n",
      "  [[ 4  4  4  5  5  5  6  6  6]\n",
      "   [ 4  4  4  5  5  5  6  6  6]\n",
      "   [ 4  4  4  5  5  5  6  6  6]\n",
      "   [ 4  4  4  5  5  5  6  6  6]\n",
      "   [ 4  4  4  5  5  5  6  6  6]\n",
      "   [ 4  4  4  5  5  5  6  6  6]]\n",
      "\n",
      "  [[ 5  5  5  6  6  6  7  7  7]\n",
      "   [ 5  5  5  6  6  6  7  7  7]\n",
      "   [ 5  5  5  6  6  6  7  7  7]\n",
      "   [ 5  5  5  6  6  6  7  7  7]\n",
      "   [ 5  5  5  6  6  6  7  7  7]\n",
      "   [ 5  5  5  6  6  6  7  7  7]]\n",
      "\n",
      "  [[ 6  6  6  7  7  7  8  8  8]\n",
      "   [ 6  6  6  7  7  7  8  8  8]\n",
      "   [ 6  6  6  7  7  7  8  8  8]\n",
      "   [ 6  6  6  7  7  7  8  8  8]\n",
      "   [ 6  6  6  7  7  7  8  8  8]\n",
      "   [ 6  6  6  7  7  7  8  8  8]]\n",
      "\n",
      "  [[ 7  7  7  8  8  8  9  9  9]\n",
      "   [ 7  7  7  8  8  8  9  9  9]\n",
      "   [ 7  7  7  8  8  8  9  9  9]\n",
      "   [ 7  7  7  8  8  8  9  9  9]\n",
      "   [ 7  7  7  8  8  8  9  9  9]\n",
      "   [ 7  7  7  8  8  8  9  9  9]]\n",
      "\n",
      "  [[ 8  8  8  9  9  9 10 10 10]\n",
      "   [ 8  8  8  9  9  9 10 10 10]\n",
      "   [ 8  8  8  9  9  9 10 10 10]\n",
      "   [ 8  8  8  9  9  9 10 10 10]\n",
      "   [ 8  8  8  9  9  9 10 10 10]\n",
      "   [ 8  8  8  9  9  9 10 10 10]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "in_h, in_w = [int(i) for i in [11, 8]]\n",
    "print(in_h, in_w)\n",
    "feat_h, feat_w = [int(i) for i in [in_h, in_w]]\n",
    "x, y = tf.meshgrid(tf.range(feat_w), tf.range(feat_h))\n",
    "x, y = [tf.reshape(i, [1, *i.get_shape(), 1]) for i in [x, y]]  # shape [1, h, w, 1]\n",
    "x, y = [tf.image.extract_image_patches(i, [1, 3, 3, 1], [1, 1, 1, 1], [1, 1, 1, 1], 'VALID') \n",
    "        for i in [x, y]] \n",
    "sess = tf.Session()\n",
    "a, b = sess.run([x, y])\n",
    "for i in [a, b]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]]\n",
      "\n",
      "  [[1.]]]\n",
      "\n",
      "\n",
      " [[[1.]]\n",
      "\n",
      "  [[1.]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sum_filter = tf.constant([1., 1., 1., 1.], dtype=tf.float32, shape=[2, 2, 1, 1])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
